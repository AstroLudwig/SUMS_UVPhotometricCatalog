{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start size: lmc 471507 smc: 263362\n"
     ]
    }
   ],
   "source": [
    "# If we choose different extinction values, how many candidates would we end up with? \n",
    "# This file reads in the extinction table we use, removes our fiducial Av, then applies a new Av to step 5 photometry\n",
    "# The dered magnitudes are saved over and our candidate selection is then run in a single cell \n",
    "# Final values are printed out at the end. \n",
    "# Primary Author: Bethany Ludwig \n",
    "# Last Updated: March 4 2025 \n",
    "\n",
    "###########\n",
    "# Change Av Here    \n",
    "lmc_Av = 0.38\n",
    "smc_Av = 0.22\n",
    "###########\n",
    "\n",
    "# Fiducial Values, need to divide our table by this to get the extinction coefficients \n",
    "lmc_Av0 = 0.38 # Fiducial is 0.38 \n",
    "smc_Av0 = 0.22 # Fiducial is 0.22 \n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from matplotlib import rc\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "#############\n",
    "# Functions #\n",
    "#############\n",
    "def AbsoluteToApparent(AbsoluteMag,distance):\n",
    "\treturn AbsoluteMag + 5 * (np.log10(distance/10)) \t\n",
    "\n",
    "def AssessColor(data_x,data_y,data_x_err,zams_blue,zams_red):\n",
    "\tcurve_x = np.array(zams_blue) - np.array(zams_red)\n",
    "\tcurve_y = np.array(zams_blue)\n",
    "\tx_zams = np.interp(data_y,np.flip(curve_y,0),np.flip(curve_x,0))\n",
    "\n",
    "\t# Check if it is blue or not\n",
    "\tcolors = []\n",
    "\tfor i,x in enumerate(data_x):\n",
    "\t\t# If left of zams than consider it overlap \n",
    "\t\t# unless we prove that it is blue within errors\n",
    "\t\tif x < (x_zams[i]):\n",
    "\t\t\tcolor = 'overlap'\n",
    "\n",
    "\t\t# If truly left of zams even within errors\n",
    "\t\t# than blue\n",
    "\t\tif x < (x_zams[i]-data_x_err[i]):\n",
    "\t\t\tcolor = 'blue'\n",
    "\n",
    "\t\t# If right of zams than consider it overlap\n",
    "\t\t# unless we prove that it is red within errors\n",
    "\t\tif x > x_zams[i]:\n",
    "\t\t\tcolor = 'overlap'\n",
    "\n",
    "\t\t# If right of zams than red\n",
    "\t\tif x > x_zams[i] + data_x_err[i]:\n",
    "\t\t\tcolor = 'red'\n",
    "\n",
    "\t\t# If color is off in narnia or a NaN\n",
    "\t\tif x < -90 or np.isnan(x):\n",
    "\t\t\tcolor = 'false'\n",
    "\n",
    "\t\tcolors.append(color)\n",
    "\treturn colors\n",
    "def Quad(X,Y):\n",
    "\treturn np.sqrt(X**2+Y**2) \n",
    "def CombinedErrors(mag_err,std):\n",
    "\t# Calculate everything in quadrature\n",
    "\tcombined_errors = Quad(mag_err,std)\n",
    "\t# Replace anything that was nan (due to no std) with just the error\n",
    "\tcombined_errors[np.isnan(combined_errors)] = mag_err[np.isnan(combined_errors)]\n",
    "\treturn combined_errors\n",
    "def DistanceToZams(data_x,data_y,zams_blue,zams_red):\n",
    "\tcurve_x = np.array(zams_blue) - np.array(zams_red)\n",
    "\tcurve_y = np.array(zams_blue)\n",
    "\tx_zams = np.interp(data_y,np.flip(curve_y,0),np.flip(curve_x,0))\n",
    "\tdistance = data_x - x_zams\n",
    "\t# If distance is an extreme value make it nan \n",
    "\tdistance[np.abs(distance) > 20] = np.nan\n",
    "\treturn distance\n",
    "def Color(df,zams):\n",
    "    colors = {\n",
    "        'uvw2 - b' : df['uvw2_dered'] - df['B_dered'],\n",
    "        'uvw2 - v' : df['uvw2_dered'] - df['V_dered'],\n",
    "        'uvw2 - i' : df['uvw2_dered'] - df['I_dered'],\n",
    "        'uvw1 - b' : df['uvw1_dered'] - df['B_dered'],\n",
    "        'uvw1 - v' : df['uvw1_dered'] - df['V_dered'],\n",
    "        'uvw1 - i' : df['uvw1_dered'] - df['I_dered'],\n",
    "        'uvm2 - b' : df['uvm2_dered'] - df['B_dered'],\n",
    "        'uvm2 - v' : df['uvm2_dered'] - df['V_dered'],\n",
    "        'uvm2 - i' : df['uvm2_dered'] - df['I_dered']\n",
    "    }\n",
    "\n",
    "    # Combined errors. Quad if both error and std are present otherwise just the error \n",
    "    combined_errs = {\n",
    "        'uvw2_err' : CombinedErrors(df['uvw2_err'], df['uvw2_std']),\n",
    "        'uvw1_err' : CombinedErrors(df['uvw1_err'], df['uvw1_std']),\n",
    "        'uvm2_err' : CombinedErrors(df['uvm2_err'], df['uvm2_std']),\n",
    "    }\n",
    "\n",
    "    color_errs = {\n",
    "        'uvw2 - b' : Quad(combined_errs['uvw2_err'] , df['e_B']),\n",
    "        'uvw2 - v' : Quad(combined_errs['uvw2_err'] , df['e_V']),\n",
    "        'uvw2 - i' : Quad(combined_errs['uvw2_err'] , df['e_I']),\n",
    "        'uvw1 - b' : Quad(combined_errs['uvw1_err'] , df['e_B']),\n",
    "        'uvw1 - v' : Quad(combined_errs['uvw1_err'] , df['e_V']),\n",
    "        'uvw1 - i' : Quad(combined_errs['uvw1_err'] , df['e_I']),\n",
    "        'uvm2 - b' : Quad(combined_errs['uvm2_err'] , df['e_B']),\n",
    "        'uvm2 - v' : Quad(combined_errs['uvm2_err'] , df['e_V']),\n",
    "        'uvm2 - i' : Quad(combined_errs['uvm2_err'] , df['e_I'])\n",
    "    }\n",
    "    color_labels = {              # x             # y                # x_err                # zams_blue  # zams_red\n",
    "        'uvw2 - b' : AssessColor(colors['uvw2 - b'],df['uvw2_dered'],color_errs['uvw2 - b'],zams['uvw2'],zams['b']),\n",
    "        'uvw2 - v' : AssessColor(colors['uvw2 - v'],df['uvw2_dered'],color_errs['uvw2 - v'],zams['uvw2'],zams['v']),\n",
    "        'uvw2 - i' : AssessColor(colors['uvw2 - i'],df['uvw2_dered'],color_errs['uvw2 - i'],zams['uvw2'],zams['i']),\n",
    "        'uvw1 - b' : AssessColor(colors['uvw1 - b'],df['uvw1_dered'],color_errs['uvw1 - b'],zams['uvw1'],zams['b']),\n",
    "        'uvw1 - v' : AssessColor(colors['uvw1 - v'],df['uvw1_dered'],color_errs['uvw1 - v'],zams['uvw1'],zams['v']),\n",
    "        'uvw1 - i' : AssessColor(colors['uvw1 - i'],df['uvw1_dered'],color_errs['uvw1 - i'],zams['uvw1'],zams['i']),\n",
    "        'uvm2 - b' : AssessColor(colors['uvm2 - b'],df['uvm2_dered'],color_errs['uvm2 - b'],zams['uvm2'],zams['b']),\n",
    "        'uvm2 - v' : AssessColor(colors['uvm2 - v'],df['uvm2_dered'],color_errs['uvm2 - v'],zams['uvm2'],zams['v']),\n",
    "        'uvm2 - i' : AssessColor(colors['uvm2 - i'],df['uvm2_dered'],color_errs['uvm2 - i'],zams['uvm2'],zams['i']),\n",
    "\n",
    "        'uvw2 - b distance' : DistanceToZams(colors['uvw2 - b'],df['uvw2_dered'],zams['uvw2'],zams['b']),\n",
    "        'uvw2 - v distance' : DistanceToZams(colors['uvw2 - v'],df['uvw2_dered'],zams['uvw2'],zams['v']),\n",
    "        'uvw2 - i distance' : DistanceToZams(colors['uvw2 - i'],df['uvw2_dered'],zams['uvw2'],zams['i']),\n",
    "        'uvw1 - b distance' : DistanceToZams(colors['uvw1 - b'],df['uvw1_dered'],zams['uvw1'],zams['b']),\n",
    "        'uvw1 - v distance' : DistanceToZams(colors['uvw1 - v'],df['uvw1_dered'],zams['uvw1'],zams['v']),\n",
    "        'uvw1 - i distance' : DistanceToZams(colors['uvw1 - i'],df['uvw1_dered'],zams['uvw1'],zams['i']),\n",
    "        'uvm2 - b distance' : DistanceToZams(colors['uvm2 - b'],df['uvm2_dered'],zams['uvm2'],zams['b']),\n",
    "        'uvm2 - v distance' : DistanceToZams(colors['uvm2 - v'],df['uvm2_dered'],zams['uvm2'],zams['v']),\n",
    "        'uvm2 - i distance' : DistanceToZams(colors['uvm2 - i'],df['uvm2_dered'],zams['uvm2'],zams['i'])\n",
    "    }\n",
    "\n",
    "    # Save Colors and Distance to the ZAMS \n",
    "    for key in color_labels.keys():\n",
    "        df[key] = color_labels[key]\n",
    "    for key in color_errs.keys():\n",
    "        df[f'{key} err'] = color_errs[key]\n",
    "\t\n",
    "    return df\n",
    "\n",
    "############\n",
    "#  Step 5  #\n",
    "############\n",
    "\n",
    "# We first need to repeat Step 5, to compute new colors given a different Av value\n",
    "# However we can ignore Vega to AB since that is saved in the unreddened photometry\n",
    "\n",
    "# Import the full catalog with gaia, and simbad run on it. \n",
    "lmc = pd.read_csv('/home/bethany/Projects/0_Data/0_SUMS_Catalogs/CompleteCatalog/Crossmatched/lmc_step5_crossmatch.csv')\n",
    "smc = pd.read_csv('/home/bethany/Projects/0_Data/0_SUMS_Catalogs/CompleteCatalog/Crossmatched/smc_step5_crossmatch.csv')\n",
    "\n",
    "# Zero out columns to be safe \n",
    "color_labels = ['uvw2 - b','uvw2 - v', 'uvw2 - i', \n",
    "                'uvw1 - b', 'uvw1 - v','uvw1 - i', \n",
    "                'uvm2 - b', 'uvm2 - v', 'uvm2 - i']\n",
    "for key in ['uvw2','uvm2','uvw1','U','B','V','I']:\n",
    "    lmc[f'{key}_dered'] = np.nan\n",
    "    smc[f'{key}_dered'] = np.nan\n",
    "lmc[color_labels] = np.nan\n",
    "\n",
    "# Load in our values from the Gordon Extinction Curve \n",
    "ref = pd.read_csv('/home/bethany/Projects/0_Data/0_SUMS_Catalogs/Reference/ExtinctionAndVega2AB.csv')\n",
    "\n",
    "# Load in the ZAMS values so we can recalculate colors \n",
    "data_dir = \"/home/bethany/Projects/0_Data/\"\n",
    "zams_smc = pd.read_csv(data_dir+'1_Models/ZAMS/ZAMS_Z0.002_ABmag.txt',sep=\"\\s+\",comment='#')\n",
    "zams_lmc = pd.read_csv(data_dir+'1_Models/ZAMS/ZAMS_Z0.006_ABmag.txt',sep=\"\\s+\",comment='#')\n",
    "# Rename phot cols to be 'UVW2' instead of 'UVW2_spec'\n",
    "zams_phot_cols = ['UVW2_spec','UVM2_spec','UVW1_spec','U_spec','B_spec','V_spec','I_spec']\n",
    "zams_smc.rename(columns={col:col.split('_')[0].lower() for col in zams_phot_cols},inplace=True)\n",
    "zams_lmc.rename(columns={col:col.split('_')[0].lower() for col in zams_phot_cols},inplace=True)\n",
    "\n",
    "# Convert models to apparent magnitudes\n",
    "lmc_distance = 50e3\n",
    "smc_distance = 60.6e3\n",
    "zams_phot_cols = ['UVW2','UVM2','UVW1','U','B','V','I']\n",
    "for col in zams_phot_cols:\n",
    "    zams_lmc[col.lower()] = AbsoluteToApparent(zams_lmc[col.lower()],lmc_distance)\n",
    "    zams_smc[col.lower()] = AbsoluteToApparent(zams_smc[col.lower()],smc_distance)\n",
    "# Only retain lower case photometric columns \n",
    "zams_lmc = zams_lmc[[col.lower() for col in zams_phot_cols]]\n",
    "zams_smc = zams_smc[[col.lower() for col in zams_phot_cols]]\n",
    "\t\n",
    "# Filters we are interested in \n",
    "allfilters = ['uvw2','uvm2','uvw1','U','B','V','I']\n",
    "\n",
    "# Apply a different Av value to Columns that have not been deredenned yet.\n",
    "# We are dividing by the fiducial value that is in the reference table to get the extinction coefficients\n",
    "for key in allfilters:\n",
    "    lmc[f'{key}_dered'] = lmc[key] - (ref.loc[ref['filter'] == key.upper(),'A_lambda (LMC)'].values[0]/lmc_Av0 * lmc_Av)\n",
    "    smc[f'{key}_dered'] = smc[key] - (ref.loc[ref['filter'] == key.upper(),'A_lambda (SMC)'].values[0]/smc_Av0 * smc_Av)\n",
    "\n",
    "# Now we need to recalculate the colors and distance to the ZAMS\n",
    "lmc = Color(lmc,zams_lmc)\n",
    "smc = Color(smc,zams_smc)\n",
    "\n",
    "print(f'Start size: lmc {lmc.shape[0]} smc: {smc.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Discovery Stars Found\n",
      "Candidates cut by parallax requirement: 8600\n",
      "Candidates cut by proper motion requirement: 34907\n",
      "Blue in more than one filter\n",
      "How many we have:  65021\n",
      "How many we lost:  633883\n",
      "Star_15\n",
      "Star_19\n",
      "End size:  65021\n",
      "0_CombineCatalog Completed\n"
     ]
    }
   ],
   "source": [
    "# From here we repeated our candidate selection process\n",
    "\n",
    "# Add column to indicate what galaxy they are in \n",
    "lmc['galaxy'] = 'lmc'\n",
    "smc['galaxy'] = 'smc'\n",
    "\n",
    "# Combine together\n",
    "df = pd.concat([lmc, smc])\n",
    "\n",
    "# Drop any unnamed columns\n",
    "df = df.drop([col for col in df.columns if 'Unnamed' in col], axis=1)\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Add Discovery Name\n",
    "discovery_ra = [15.24876,14.25651,14.41704,16.00199,77.20574,76.19464,82.00481,86.86671,81.58229,77.16778,77.84628,83.11642,81.8678,80.916,84.05355,83.89011,81.69701,80.48712,78.34581,84.13771,15.48006,15.84282,15.92665,12.68916,15.97596]\n",
    "discovery_dec = [-72.62048,-72.60092,-71.98791,-72.27852,-69.0916,-69.04014,-69.99687,-69.1021,-69.37607,-69.18455,-69.8981,-70.30682,-68.68436,-68.61127,-69.45609,-70.31835,-68.82376,-69.42087,-69.37446,-69.44082,-72.45029,-72.10988,-72.02792,-73.26791,-72.12816]\n",
    "discovery_coord = SkyCoord(discovery_ra, discovery_dec, unit='deg')\n",
    "discovery_name = ['Star_1','Star_2','Star_3','Star_4','Star_5','Star_6','Star_7','Star_8','Star_9','Star_10','Star_11','Star_12','Star_13','Star_14','Star_15','Star_16','Star_17','Star_18','Star_19','Star_20','Star_21','Star_22','Star_23','Star_24','Star_25']\n",
    "\n",
    "df_co = SkyCoord(df['ra'], df['dec'], unit='deg')\n",
    "\n",
    "for name, coordinate in zip(discovery_name, discovery_coord):\n",
    "    distances = coordinate.separation(df_co).arcsecond\n",
    "    min_distance = np.min(distances)\n",
    "    row = df[distances == min_distance]\n",
    "    # If no matching source is found, print the minimum distance and the name of the source\n",
    "    if min_distance > 0.1:\n",
    "        print(min_distance)\n",
    "        print(name)\n",
    "    # Otherwise add it to the dataframe\n",
    "    else:\n",
    "        df.loc[row.index,'discovery_name'] = name\n",
    "        \n",
    "def check_stars(df):\n",
    "    # Make sure we have all the discovery stars \n",
    "    discovery_names = ['Star_1','Star_2','Star_3','Star_4','Star_5','Star_6','Star_7','Star_8','Star_9','Star_10','Star_11','Star_12','Star_13','Star_14','Star_15','Star_16','Star_17','Star_18','Star_19','Star_20','Star_21','Star_22','Star_23','Star_24','Star_25']\n",
    "    c = 0\n",
    "    for star in discovery_names:\n",
    "        if star not in df.discovery_name.unique():\n",
    "            print(star)\n",
    "            c += 1\n",
    "    if c == 0:\n",
    "        print (\"All Discovery Stars Found\")\n",
    "check_stars(df)\n",
    "\n",
    "initial_df = df.copy()\n",
    "\n",
    "# Require that the gaia checks are set to 'no'\n",
    "# How many potential candidates will be cut by gaia? \n",
    "print(f'Candidates cut by parallax requirement: {df[df[\"gaia_px_cut\"] == \"yes\"].shape[0]}')\n",
    "print(f'Candidates cut by proper motion requirement: {df[df[\"gaia_pm_cut\"] == \"yes\"].shape[0]}')\n",
    "\n",
    "# Uncomment if you don't want to cut until the end.\n",
    "# df[\"would_be_cut_by_gaia\"] = \"no\"\n",
    "# df.loc[df[\"gaia_px_cut\"] == \"yes\", \"would_be_cut_by_gaia\"] = \"yes\"\n",
    "# df.loc[df[\"gaia_pm_cut\"] == \"yes\", \"would_be_cut_by_gaia\"] = \"yes\"\n",
    "\n",
    "df = df[df[\"gaia_px_cut\"] == \"no\"]\n",
    "df = df[df[\"gaia_pm_cut\"] == \"no\"].reset_index(drop=True)\n",
    "\n",
    "# Define the color combination labels\n",
    "color_labels = ['uvw2 - b','uvw2 - v', 'uvw2 - i', \n",
    "                'uvw1 - b', 'uvw1 - v','uvw1 - i', \n",
    "                'uvm2 - b', 'uvm2 - v', 'uvm2 - i']\n",
    "\n",
    "# Count how many color combinations are 'blue' \n",
    "n_blue = df[color_labels].isin(['blue']).sum(axis=1)\n",
    "df['n_blue'] = n_blue\n",
    "\n",
    "# Remove sources that are not blue in any filter\n",
    "n_not_blue = len(df[df['n_blue'] == 0])\n",
    "df = df[~(df['n_blue'] == 0)].reset_index(drop=True)\n",
    "\n",
    "# Count how many color combinations are 'overlap'\n",
    "df['n_overlap'] = df[color_labels].isin(['overlap']).sum(axis=1)\n",
    "\n",
    "# Count how many color combinations are 'red'\n",
    "df['n_red'] = df[color_labels].isin(['red']).sum(axis=1)\n",
    "\n",
    "print('Blue in more than one filter')\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many we lost: ',n_not_blue)\n",
    "check_stars(df)\n",
    "\n",
    "print('End size: ', df.shape[0])\n",
    "combine_catalog_df = df.copy() \n",
    "print('0_CombineCatalog Completed')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stars brighter than Stripped Star models\n",
      "How many we have:  64652\n",
      "How many we lost:  369\n",
      "Star_15\n",
      "Star_19\n",
      "Stars fainter in UV than 19 mag\n",
      "How many we have:  30029\n",
      "How many we lost:  34623\n",
      "Star_15\n",
      "Star_19\n",
      "Stars with mag error within 5sigma\n",
      "How many we lost because all magnitudes had high errors:  89\n",
      "How many we lost because all blue colors were associated with high magnitude errors:  8184\n",
      "How many we have:  21756\n",
      "Star_15\n",
      "Star_19\n",
      "Stars without enough magnitudes in UV and Optical\n",
      "How many we have:  12616\n",
      "How many we lost:  9140\n",
      "Star_15\n",
      "Star_19\n",
      "1_MagnitudeReductions Completed\n",
      "How many stars we have:  12616\n",
      "All Remaining Discovery Stars After Magnitude Reductions Have Been Found\n",
      "\n",
      "\n",
      "Solving m2\n",
      "Checking Colors: ['m2 - b', 'm2 - v', 'm2 - i']\n",
      "Calculating difference for: \"w2 - m2\"\n",
      "Calculating difference for: \"m2 - w1\"\n",
      "\n",
      "Solving w1\n",
      "Checking Colors: ['w1 - b', 'w1 - v', 'w1 - i']\n",
      "Calculating difference for: \"m2 - w1\"\n",
      "Calculating difference for: \"w1 - u\"\n",
      "\n",
      "Solving b\n",
      "Checking Colors: ['w2 - b', 'm2 - b', 'w1 - b']\n",
      "Calculating difference for: \"u - b\"\n",
      "Calculating difference for: \"b - v\"\n",
      "\n",
      "Solving v\n",
      "Checking Colors: ['w2 - v', 'm2 - v', 'w1 - v']\n",
      "Calculating difference for: \"b - v\"\n",
      "Calculating difference for: \"v - i\"\n",
      "\n",
      "How many we have:  10479\n",
      "How many we lost:  2137\n",
      "All Remaining Discovery Stars After Magnitude Reductions Have Been Found\n",
      "How many we have:  10205\n",
      "How many we lost:  274\n",
      "All Remaining Discovery Stars After Magnitude Reductions Have Been Found\n",
      "How many we have:  9115\n",
      "How many were categorized as mismatched:  1090\n",
      "All Remaining Discovery Stars After Magnitude Reductions Have Been Found\n",
      "How many we have:  6328\n",
      "How many we lost:  2787\n",
      "All Remaining Discovery Stars After Magnitude Reductions Have Been Found\n",
      "How many we have:  5889\n",
      "How many we lost:  439\n",
      "All Remaining Discovery Stars After Magnitude Reductions Have Been Found\n",
      "How many we have:  4350\n",
      "How many we lost:  1539\n",
      "Star_17\n",
      "Star_25\n",
      "4350 stars remaining\n",
      "8266 stars cut\n",
      "galaxy\n",
      "lmc    2608\n",
      "smc    1742\n",
      "Name: count, dtype: int64\n",
      "2_SEDReductions Completed\n",
      "Initial Size:  4350\n",
      "After initial cuts:  829\n",
      "Av in the SMC:  0.22\n",
      "Candidates in the SMC:  301\n",
      "Av in the LMC:  0.38\n",
      "Candidates in the LMC:  528\n",
      "Total Percentages: \n",
      "cut\n",
      "B-E     0.223160\n",
      "B-G     0.272618\n",
      "VB-E    0.127865\n",
      "VB-G    0.376357\n",
      "Name: proportion, dtype: float64\n",
      " \n",
      "Total Values: \n",
      "cut\n",
      "B-E     185\n",
      "B-G     226\n",
      "VB-E    106\n",
      "VB-G    312\n",
      "Name: count, dtype: int64\n",
      " \n",
      "LMC Values: \n",
      "cut\n",
      "B-E      94\n",
      "B-G     120\n",
      "VB-E     78\n",
      "VB-G    236\n",
      "Name: count, dtype: int64\n",
      " \n",
      "SMC Values: \n",
      "cut\n",
      "B-E      91\n",
      "B-G     106\n",
      "VB-E     28\n",
      "VB-G     76\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the indices of stars that are brighter than Ylva's models \n",
    "bright_cutoff = 14\n",
    "# Calculate in all UV filters in case one is missing\n",
    "index_bright_uv = list(df[(df['uvm2_dered'] < bright_cutoff)].index) + list(df[(df['uvw2_dered'] < bright_cutoff)].index) + list(df[(df['uvw1_dered'] < bright_cutoff)].index)\n",
    "# Drop duplicates \n",
    "index_bright_uv = list(set(index_bright_uv))\n",
    "\n",
    "# Remove these indices from the catalog\n",
    "df = df.drop(index_bright_uv).reset_index(drop=True)\n",
    "\n",
    "print('Stars brighter than Stripped Star models')\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many we lost: ',len(index_bright_uv))\n",
    "check_stars(df)\n",
    "\n",
    "\n",
    "# Get the indices of stars that are brighter than Ylva's models \n",
    "faint_cutoff = 19\n",
    "# Calculate in all UV filters in case one is missing\n",
    "index_faint_uv = list(df[(df['uvm2_dered'] > faint_cutoff)].index) + list(df[(df['uvw2_dered'] > faint_cutoff)].index) + list(df[(df['uvw1_dered'] > faint_cutoff)].index)\n",
    "# Drop duplicates \n",
    "index_faint_uv = list(set(index_faint_uv))\n",
    "\n",
    "# Remove these indices from the catalog\n",
    "df = df.drop(index_faint_uv).reset_index(drop=True)\n",
    "\n",
    "print('Stars fainter in UV than 19 mag')\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many we lost: ',len(index_faint_uv))\n",
    "check_stars(df)\n",
    "\n",
    "\n",
    "print('Stars with mag error within 5sigma')\n",
    "# If mag error is above our limit set both mag and mag error to 0\n",
    "max_mag_err = 0.217\n",
    "\n",
    "mag_cols = ['uvw2_dered','uvm2_dered','uvw1_dered','U_dered','B_dered','V_dered','I_dered']\n",
    "error_cols = ['uvw2_err','uvm2_err','uvw1_err','e_U','e_B','e_V','e_I']\n",
    "color_cols = [['uvw2 - b','uvw2 - v','uvw2 - i'],\n",
    "                 ['uvm2 - b','uvm2 - v','uvm2 - i'],\n",
    "                 ['uvw1 - b','uvw1 - v','uvw1 - i'],\n",
    "                 ['u','u','u'],\n",
    "                 ['uvw2 - b','uvm2 - b','uvw1 - b'],\n",
    "                 ['uvw2 - v','uvm2 - v','uvw1 - v'],\n",
    "                 ['uvw2 - i','uvm2 - i','uvw1 - i']]\n",
    "color_labels = ['uvw2 - b','uvw2 - v', 'uvw2 - i', \n",
    "                'uvw1 - b', 'uvw1 - v','uvw1 - i', \n",
    "                'uvm2 - b', 'uvm2 - v', 'uvm2 - i']\n",
    "\n",
    "for mag,err,color in zip(mag_cols,error_cols,color_cols):\n",
    "    # Columns we want to set to nan\n",
    "    cols = [mag,err] + color \n",
    "    # We don't calculate color for U\n",
    "    if mag == 'U_dered':\n",
    "        cols = [mag,err]\n",
    "        \n",
    "    # If the mag is above the mag error, set the mag, error, and color columns to nan. \n",
    "    df.loc[df[err] > max_mag_err,cols] = np.nan\n",
    "\n",
    "# Convert 0's back to NaNs \n",
    "df = df.replace(0,np.nan)\n",
    "\n",
    "# Calculate how many nans exist in a row \n",
    "n_mag_err = df[mag_cols].isna().sum(axis=1)\n",
    "\n",
    "# If all 7 mag columns are 0 drop\n",
    "print(f'How many we lost because all magnitudes had high errors: ',df[(n_mag_err == 7)].shape[0])\n",
    "df = df[~(n_mag_err == 7)].reset_index(drop=True)\n",
    "\n",
    "# Recalculate n_blue \n",
    "n_blue = df[color_labels].isin(['blue']).sum(axis=1)\n",
    "df['n_blue_initial'] = df['n_blue']\n",
    "df['n_blue'] = n_blue\n",
    "\n",
    "# if n_blue is now 0 then drop it \n",
    "print(f'How many we lost because all blue colors were associated with high magnitude errors: ',df[df['n_blue'] == 0].shape[0])\n",
    "df = df[df['n_blue'] != 0].reset_index(drop=True)\n",
    "\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "check_stars(df)\n",
    "\n",
    "optical_columns = ['U_dered','B_dered','V_dered','I_dered']\n",
    "uv_columns = ['uvw2_dered','uvm2_dered','uvw1_dered']\n",
    "\n",
    "enough_points = []\n",
    "for ind,row in df.iterrows():\n",
    "    # How many optical mags are there\n",
    "    n_optical = row[optical_columns].count()\n",
    "    # How many UV mags are there \n",
    "    n_uv = row[uv_columns].count()\n",
    "    # Need two in both \n",
    "    if n_optical >= 3 and n_uv >= 2: \n",
    "        enough_points.append(ind)\n",
    "\n",
    "print('Stars without enough magnitudes in UV and Optical')\n",
    "print(f'How many we have: ',len(enough_points))\n",
    "print(f'How many we lost: ',df.shape[0] - len(enough_points))\n",
    "\n",
    "df = df[df.index.isin(enough_points)].reset_index(drop=True)        \n",
    "check_stars(df)\n",
    "\n",
    "mag_reduced_df = df.copy()\n",
    "\n",
    "# Save\n",
    "print('1_MagnitudeReductions Completed')\n",
    "\n",
    "# Make a key\n",
    "df['key'] = np.arange(df.shape[0])\n",
    "\n",
    "# Rename filters for simplicity, we can rename them back at the end\n",
    "df = df.rename(columns={'uvw2_dered':'w2','uvm2_dered':'m2','uvw1_dered':'w1',\n",
    "                                          'U_dered':'u','B_dered':'b','V_dered':'v','I_dered':'i',\n",
    "                                          'uvw2 - b':'w2 - b', 'uvw2 - v':'w2 - v', 'uvw2 - i':'w2 - i',\n",
    "                                          'uvw1 - b':'w1 - b', 'uvw1 - v':'w1 - v', 'uvw1 - i':'w1 - i', \n",
    "                                          'uvm2 - b':'m2 - b', 'uvm2 - v':'m2 - v', 'uvm2 - i':'m2 - i'})\n",
    "\n",
    "# Select keys\n",
    "optical_columns = ['u','b','v','i']\n",
    "uv_columns = ['w2','m2','w1']\n",
    "color_columns = ['w2 - b', 'w2 - v', 'w2 - i',\n",
    "                'm2 - b', 'm2 - v', 'm2 - i',\n",
    "                'w1 - b', 'w1 - v', 'w1 - i']\n",
    "\n",
    "# Make sure we have all the discovery stars except Star 15 (and now Star 19) which we lost in the last notebook \n",
    "def check_stars(df):\n",
    "    # Make sure we have all the discovery stars \n",
    "    discovery_names = ['Star_1','Star_2','Star_3','Star_4','Star_5','Star_6','Star_7','Star_8','Star_9','Star_10','Star_11','Star_12','Star_13','Star_14','Star_16','Star_17','Star_18','Star_20','Star_21','Star_22','Star_23','Star_24','Star_25']\n",
    "    c = 0\n",
    "    for star in discovery_names:\n",
    "        if star not in df.discovery_name.unique():\n",
    "            print (star)\n",
    "            c += 1\n",
    "    if c == 0:\n",
    "        print (\"All Remaining Discovery Stars After Magnitude Reductions Have Been Found\")\n",
    "\n",
    "# Print how many stars we have\n",
    "print(\"How many stars we have: \",df.shape[0])\n",
    "\n",
    "# Read in synthetic photometry\n",
    "names = ['Minit_strip','M_MS','frac_MS','U','B','V','R','I','UVM2','UVW2','UVW1']\n",
    "\n",
    "synth_photom_file = '/home/bethany/Projects/0_Data/1_Models/Stripped_Stars/photometry_CMFGEN_composites.txt'\n",
    "sf = pd.read_csv(synth_photom_file,comment='#',delimiter='\\t',names=names)\n",
    "\n",
    "# Make dictionary of the minimum and maximum difference between different filters\n",
    "max_mag_err = 0.217\n",
    "min_diff = {'w2 - m2': np.min(sf.UVW2-sf.UVM2) - max_mag_err,\n",
    "            'm2 - w1': np.min(sf.UVM2-sf.UVW1) - max_mag_err,\n",
    "            'w1 - u': np.min(sf.UVW1-sf.U) - max_mag_err,\n",
    "            'u - b': np.min(sf.U-sf.B) - max_mag_err,\n",
    "            'b - v': np.min(sf.B-sf.V) - max_mag_err,\n",
    "            'v - i': np.min(sf.V-sf.I) - max_mag_err,\n",
    "            # Additional UV - Optical Filters\n",
    "            'w1 - b': np.min(sf.UVW1-sf.B) - max_mag_err,\n",
    "            'm2 - u': np.min(sf.UVM2-sf.U) - max_mag_err,\n",
    "            'm2 - b': np.min(sf.UVM2-sf.B) - max_mag_err,\n",
    "           }\n",
    "\n",
    "max_diff = {'w2 - m2': np.max(sf.UVW2-sf.UVM2) + max_mag_err,\n",
    "            'm2 - w1': np.max(sf.UVM2-sf.UVW1) + max_mag_err,\n",
    "            'w1 - u': np.max(sf.UVW1-sf.U) + max_mag_err,\n",
    "            'u - b': np.max(sf.U-sf.B) + max_mag_err,\n",
    "            'b - v': np.max(sf.B-sf.V) + max_mag_err,\n",
    "            'v - i': np.max(sf.V-sf.I) + max_mag_err,\n",
    "            # Additional UV - Optical Filters\n",
    "            'w1 - b': np.max(sf.UVW1-sf.B) + max_mag_err,\n",
    "            'm2 - u': np.max(sf.UVM2-sf.U) + max_mag_err,\n",
    "            'm2 - b': np.max(sf.UVM2-sf.B) + max_mag_err,\n",
    "           }\n",
    "\n",
    "check_stars(df)\n",
    "\n",
    "size = df.shape[0]\n",
    "# Get rows where only one filter made it blue\n",
    "blue_in_one = df[df['n_blue'] <= 3].copy()\n",
    "\n",
    "# Compare adjacent mags to see if the filter is super different from the sed \n",
    "bad_filter_index = []\n",
    "\n",
    "# For the filters on the ends, uvw2 and i, you only need to compare one color\n",
    "filter_1 = ['w2','v']\n",
    "filter_2 = ['m2','i']\n",
    "filter_color = ['w2','i']\n",
    "\n",
    "for f1, f2, fc in zip(filter_1,filter_2,filter_color):\n",
    "    # Get all color combos for a specific filter \n",
    "    # For example, get all the w2 - b, w2 - v, w2 - i for w2\n",
    "    c = list(filter(lambda x: fc in x,color_columns))\n",
    "    # Get everything where the respective filter is blue \n",
    "    blue = blue_in_one[(blue_in_one[c[0]] == 'blue') & (blue_in_one[c[1]] == 'blue') & (blue_in_one[c[2]] == 'blue')]\n",
    "    # Calculate the difference between the filter and its adjacent filter\n",
    "    diff = blue[f'{f1}'] - blue[f'{f2}']\n",
    "    # Compare to synthetic photometry      \n",
    "    bad = blue[(diff > max_diff[f'{f1} - {f2}']) | (diff < min_diff[f'{f1} - {f2}']) ]\n",
    "    bad_keys = bad['key'].values\n",
    "    print('')\n",
    "    bad_filter_index.append(bad_keys)\n",
    "\n",
    "# For all the other filters you need to compare whats on the left and the right \n",
    "filters = ['w2','m2','w1','u','b','v','i']          \n",
    "\n",
    "for i in np.arange(6):\n",
    "    # Skip the ends\n",
    "    if filters[i] == 'w2' or filters[i] == 'i' or filters[i] == 'u':\n",
    "        continue\n",
    "    # The filter you're considering\n",
    "    f0 = filters[i]\n",
    "    # The previous filter\n",
    "    f1 = filters[i-1]\n",
    "    # The next filter\n",
    "    f2 = filters[i+1]\n",
    "    print(f'Solving {f0}')\n",
    "    # Get colors \n",
    "    c = list(filter(lambda x: f0 in x,color_columns))\n",
    "    print(f'Checking Colors: {c}')\n",
    "    # Get everything where the respective filter is blue \n",
    "    blue = blue_in_one[(blue_in_one[c[0]] == 'blue') & (blue_in_one[c[1]] == 'blue') & (blue_in_one[c[2]] == 'blue')] \n",
    "    # Calculate differences\n",
    "    print(f'Calculating difference for: \"{f1} - {f0}\"')\n",
    "    diff_1 = blue[f'{f1}'] - blue[f'{f0}']\n",
    "    print(f'Calculating difference for: \"{f0} - {f2}\"')\n",
    "    diff_2 = blue[f'{f0}'] - blue[f'{f2}']\n",
    "    # Calculate synthetic differences\n",
    "    synth_1 = [min_diff[f'{f1} - {f0}'], max_diff[f'{f1} - {f0}']]\n",
    "    synth_2 = [min_diff[f'{f0} - {f2}'], max_diff[f'{f0} - {f2}']]\n",
    "    # Compare                    The Left                                        The Right\n",
    "    bad = blue[(diff_1 < synth_1[0]) | (diff_1 > synth_1[1]) | (diff_2 < synth_2[0]) | (diff_2 > synth_2[1])]\n",
    "    bad_keys = bad['key'].values\n",
    "    if len(bad_keys) == 0: \n",
    "        print('Check Filter')\n",
    "        print(f0)\n",
    "    print('')\n",
    "    # Append\n",
    "    bad_filter_index.append(bad_keys)\n",
    "    \n",
    "# Flatten the index\n",
    "bad_filter_index = [item for row in bad_filter_index for item in row]\n",
    "# Sort the index \n",
    "bad_filter_index = np.sort(bad_filter_index)\n",
    "\n",
    "df = df[~df['key'].isin(bad_filter_index)]\n",
    "\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many we lost: ',size-df.shape[0])\n",
    "check_stars(df)\n",
    "\n",
    "size = df.shape[0]\n",
    "# Mismatch #1: UV and Optical components of SED are fairly flat but there's a large discrepency between them\n",
    "\n",
    "# If all the mags are within the max allowed error, we consider it 'flat'\n",
    "flat_std = max_mag_err\n",
    "flat_mag_jump = 1. + max_mag_err\n",
    "\n",
    "flat_jump_index = []\n",
    "\n",
    "for ind,row in df.iterrows():\n",
    "    uv = row[uv_columns].values\n",
    "    opt = row[optical_columns].values\n",
    "    \n",
    "    if np.nanstd(uv) < flat_std and np.nanstd(opt) < flat_std:\n",
    "        # If you have a flat sed look for a big jump \n",
    "        if np.abs(np.nanmean(uv) - np.nanmean(opt)) > flat_mag_jump:\n",
    "            flat_jump_index.append(row['key'])\n",
    "            \n",
    "# Remove from sample \n",
    "df = df[~df['key'].isin(flat_jump_index)]\n",
    "\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many we lost: ',size - df.shape[0])\n",
    "check_stars(df)    \n",
    "\n",
    "size = df.shape[0]\n",
    "# Mismatch #2: Check either UVW1 or UVW2 against U or B to see if there's a large jump \n",
    "def not_in_bin(row,uv_filter,optical_filter):\n",
    "    diff = row[uv_filter] - row[optical_filter]\n",
    "    if diff < min_diff[f'{uv_filter} - {optical_filter}'] or diff > max_diff[f'{uv_filter} - {optical_filter}']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def exists(row,Filter):\n",
    "    return np.isfinite(row[Filter])\n",
    "\n",
    "mismatch_index = []\n",
    "\n",
    "for i,r in df.iterrows():\n",
    "\n",
    "    # Ideal case: UVW1, U, and B, all exist. \n",
    "    if exists(r,'w1') and exists(r,'u') and exists(r,'b'):\n",
    "        # If UVW1 - U and UVW1 - B are both not in synthetic bin then drop\n",
    "        if not_in_bin(r,'w1','u') and not_in_bin(r,'w1','b'):\n",
    "            mismatch_index.append(r['key'])\n",
    "    \n",
    "    # UVW1 and U exist, but B does not.\n",
    "    if exists(r,'w1') and exists(r,'u') and not exists(r,'b'):\n",
    "        # If UVW1 - U is not in synthetic bin then drop\n",
    "        if not_in_bin(r,'w1','u'):\n",
    "            mismatch_index.append(r['key'])\n",
    "            \n",
    "    # UVW1 and B exist, but U does not. \n",
    "    if exists(r,'w1') and exists(r,'b') and not exists(r,'u'):\n",
    "        # If UVW1 - B is not in synthetic bin then drop\n",
    "        if not_in_bin(r,'w1','b'):\n",
    "            mismatch_index.append(r['key'])    \n",
    "    \n",
    "    # UVM2, U, and B, exist, but UVW1 does not. \n",
    "    if exists(r,'m2') and exists(r,'u') and exists(r,'b') and not exists(r,'w1'):\n",
    "        # If UVM2 - U and UVM2 - B are both not in synthetic bin then drop\n",
    "        if not_in_bin(r,'m2','u') and not_in_bin(r,'m2','b'):\n",
    "            mismatch_index.append(r['key']) \n",
    "            \n",
    "    # UVM2 and U exist, but UVW1 and B do not.\n",
    "    if exists(r,'m2') and exists(r,'u') and not exists(r,'w1') and not exists(r,'b'):\n",
    "        # If UVM2 - U is not in synthetic bin then drop\n",
    "        if not_in_bin(r,'m2','u'):\n",
    "            mismatch_index.append(r['key'])     \n",
    "\n",
    "    # UVM2 and B exist, but UVW1 and U do not. \n",
    "    if exists(r,'m2') and exists(r,'b') and not exists(r,'w1') and not exists(r,'u'):\n",
    "        # If UVM2 - B is not in synthetic bin then drop\n",
    "        if not_in_bin(r,'m2','b'):\n",
    "            mismatch_index.append(r['key'])    \n",
    "            \n",
    "df = df[~df['key'].isin(mismatch_index)]\n",
    "\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many were categorized as mismatched: ',size - df.shape[0])\n",
    "check_stars(df)  \n",
    "\n",
    "size = df.shape[0]\n",
    "red_index = []\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    y = np.array(row[optical_columns].values).astype(float)\n",
    "    # Calculate derivatives\n",
    "    d = np.diff(y)\n",
    "    # If derivatives are negative 2 or more times (indicating positive slope for mags) then save\n",
    "    n = len(d[np.isfinite(d) & (d<0)])\n",
    "    if n >= 2:\n",
    "        red_index.append(row['key'])\n",
    "\n",
    "df = df[~df['key'].isin(red_index)].reset_index(drop=True)\n",
    "\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many we lost: ',size-df.shape[0])\n",
    "check_stars(df)  \n",
    "\n",
    "\n",
    "vf = df.copy()\n",
    "\n",
    "def not_in_bin(row,uv_filter,optical_filter):\n",
    "    diff = row[uv_filter] - row[optical_filter]\n",
    "    if diff < min_diff[f'{uv_filter} - {optical_filter}'] or diff > max_diff[f'{uv_filter} - {optical_filter}']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "variable_index = []\n",
    "filters = ['w2','m2','w1','u','b','v','i']\n",
    "for ind,row in vf.iterrows():\n",
    "    # Get the sed\n",
    "    sed = row[filters]\n",
    "    # Take the derivatives         \n",
    "    div = np.abs(np.diff(sed))\n",
    "    # Compare to allowed differences \n",
    "    compare = [not_in_bin(row,f1,f2) for f1,f2 in zip(filters[:-1],filters[1:])]\n",
    "    # Where do the bumps occur? \n",
    "    loc = np.where(compare)[0]\n",
    "    # How many bumps are there?\n",
    "    n_bumps = len(loc)\n",
    "    if n_bumps == 0: \n",
    "        continue\n",
    "    # If there are three or more bumps it's automatically variable \n",
    "    if n_bumps >= 3:\n",
    "        variable_index.append(row.key)\n",
    "        \n",
    "    # The location of the bumps tell us which filters are involved \n",
    "    # Zero out colors related to that filter and see if it is still blue \n",
    "    # For instance: W2 - M2 is the first element in the div array\n",
    "        \n",
    "    # If there are two bumps and they are next to each other: \n",
    "    if n_bumps == 2 and (loc[1] == loc[0] - 1 or loc[1] == loc[0] + 1): \n",
    "        # UVM2 is connected\n",
    "        if loc[0] == 0 and loc[1] == 1:\n",
    "            vf.loc[vf.key==row.key,color_columns[1]] = np.nan\n",
    "        # UVW1 is connected\n",
    "        if loc[0] == 1 and loc[1] == 2:\n",
    "            vf.loc[vf.key==row.key,color_columns[2]] = np.nan\n",
    "        # B is connected, zero out related colors\n",
    "        if loc[0] == 3 and loc[1] == 4:\n",
    "            vf.loc[vf.key==row.key,color_columns[4]] = np.nan\n",
    "        # V is connected, zero out related colors\n",
    "        if loc[0] == 4 and loc[1] == 5:\n",
    "            vf.loc[vf.key==row.key,color_columns[5]] = np.nan\n",
    "    # If there is one bump or they are not connected\n",
    "    else:\n",
    "        # UVW2 and UVM2 \n",
    "        if 0 in loc:\n",
    "            vf.loc[vf.key==row.key,color_columns[0] + color_columns[1]] = np.nan\n",
    "        # UVM2 and UVW1 \n",
    "        if 1 in loc: \n",
    "            vf.loc[vf.key==row.key,color_columns[1] + color_columns[2]] = np.nan\n",
    "        # UVW1 and U (we don't color by U)\n",
    "        if 2 in loc: \n",
    "            vf.loc[vf.key==row.key,color_columns[2]] = np.nan\n",
    "        # U and B (we don't color by U)\n",
    "        if 3 in loc: \n",
    "            vf.loc[vf.key==row.key,color_columns[4]] = np.nan\n",
    "        # B and V \n",
    "        if 4 in loc: \n",
    "            vf.loc[vf.key==row.key,color_columns[4] + color_columns[5]] = np.nan\n",
    "        # V and I \n",
    "        if 5 in loc: \n",
    "            vf.loc[vf.key==row.key,color_columns[5] + color_columns[6]] = np.nan\n",
    "            \n",
    "# Recalculate to see what is still blue \n",
    "n_blue = vf[color_columns].isin(['blue']).sum(axis=1)\n",
    "\n",
    "# Find out which rows are no longer blue \n",
    "nolongerblue = vf.loc[n_blue == 0,'key']\n",
    "\n",
    "# Combine Variable Index and No Longer Blue, Remove Duplicates\n",
    "variable_index = np.sort(np.unique(np.append(variable_index,nolongerblue)))\n",
    "\n",
    "# Drop variables\n",
    "df = df[~df['key'].isin(variable_index)]\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many we lost: ',len(variable_index))\n",
    "check_stars(df)  \n",
    "\n",
    "\n",
    "# Change all color combos with 'i' to not be blue. \n",
    "i_df = df.copy()\n",
    "\n",
    "for color in ['w2 - i','w1 - i', 'm2 - i']:\n",
    "    i_df[color] = i_df[color].replace('blue',np.nan)\n",
    "\n",
    "# Recalculate to see what is still blue \n",
    "n_blue = i_df[color_columns].isin(['blue']).sum(axis=1)\n",
    "\n",
    "# Find out which rows are no longer blue \n",
    "bad_i_index = i_df.loc[n_blue == 0,'key']\n",
    "\n",
    "# Drop variables\n",
    "df = df[~df['key'].isin(bad_i_index)]\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many we lost: ',len(bad_i_index))\n",
    "check_stars(df)  \n",
    "\n",
    "#Reread in and calculate the number of jumps for everything: \n",
    "df = mag_reduced_df.copy() \n",
    "\n",
    "# Rename filters for simplicity, we can rename them back at the end\n",
    "df = df.rename(columns={'uvw2_dered':'w2','uvm2_dered':'m2','uvw1_dered':'w1',\n",
    "                                          'U_dered':'u','B_dered':'b','V_dered':'v','I_dered':'i',\n",
    "                                          'uvw2 - b':'w2 - b', 'uvw2 - v':'w2 - v', 'uvw2 - i':'w2 - i',\n",
    "                                          'uvw1 - b':'w1 - b', 'uvw1 - v':'w1 - v', 'uvw1 - i':'w1 - i', \n",
    "                                          'uvm2 - b':'m2 - b', 'uvm2 - v':'m2 - v', 'uvm2 - i':'m2 - i'})\n",
    "\n",
    "#Recalculate the number of bumps for this sample and save it as a column: \n",
    "filters = ['w2','m2','w1','u','b','v','i']\n",
    "n_bumps = []\n",
    "for ind,row in df.iterrows():\n",
    "    # Get the sed\n",
    "    sed = row[filters]\n",
    "    # Take the derivatives         \n",
    "    div = np.abs(np.diff(sed))\n",
    "    # Compare to allowed differences \n",
    "    compare = [not_in_bin(row,f1,f2) for f1,f2 in zip(filters[:-1],filters[1:])]\n",
    "    # Where do the bumps occur? \n",
    "    loc = np.where(compare)[0]\n",
    "    # How many bumps are there?\n",
    "    n_bumps.append(len(loc))\n",
    "\n",
    "\n",
    "# Do any cuts overlap?\n",
    "drop_index = [bad_filter_index , flat_jump_index , mismatch_index , red_index , variable_index , bad_i_index]\n",
    "drop_name = ['bad_filter','flat_jump','mismatch','red','variable','bad_i']\n",
    "\n",
    "# Re-Read in magnitude reduced files \n",
    "df = mag_reduced_df.copy() \n",
    "\n",
    "# Make a key\n",
    "df['key'] = np.arange(df.shape[0])\n",
    "\n",
    "# Add the number of bumps to the dataframe\n",
    "df['n_bumps'] = n_bumps\n",
    "\n",
    "\n",
    "# Make a cut column \n",
    "df['cut'] = ''\n",
    "\n",
    "# Fill the cut column \n",
    "for index, name in zip(drop_index,drop_name):\n",
    "    df.loc[df['key'].isin(index),'cut'] = name\n",
    "\n",
    "print(f'{df[df.cut == \"\"].shape[0]} stars remaining')\n",
    "print(f'{df[df.cut != \"\"].shape[0]} stars cut')\n",
    "print(df[df.cut == \"\"].galaxy.value_counts())\n",
    "\n",
    "sedreductions_df = df.copy()\n",
    "print('2_SEDReductions Completed')\n",
    "\n",
    "\n",
    "# Turn empty spaces in df into nans \n",
    "df = sedreductions_df.copy()\n",
    "df = df.replace('',np.nan)\n",
    "df[df.cut.isna()]\n",
    "\n",
    "# Drop anything that was cut from the sample\n",
    "df = df[df.cut.isna()]\n",
    "\n",
    "print('Initial Size: ', df.shape[0])\n",
    "\n",
    "# Drop any unnamed columns\n",
    "df = df.drop([col for col in df.columns if 'Unnamed' in col], axis=1)\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Replace number columns that have nans with 0\n",
    "nan_cols = ['uvw2_num2p5', 'uvm2_num2p5', 'uvw1_num2p5','uvw2_num1', 'uvm2_num1', 'uvw1_num1']\n",
    "[df.fillna({col:0}, inplace=True) for col in nan_cols]\n",
    "\n",
    "# Add a column taking maximum number of neighbors within 2.5\"\n",
    "df['max_2p5'] = df[['uvw2_num2p5', 'uvm2_num2p5', 'uvw1_num2p5']].max(axis=1)\n",
    "\n",
    "# Add a column taking maximum number of neighbors are within 1\"\n",
    "df['max_1'] = df[['uvw2_num1', 'uvm2_num1', 'uvw1_num1']].max(axis=1)\n",
    "\n",
    "# Add a column taking minimum distance of closest stars:\n",
    "df['closest'] = df[['uvw2_closest_min', 'uvm2_closest_min', 'uvw1_closest_min']].min(axis=1)\n",
    "\n",
    "# Add a column taking minimium and average of the UV flux fractions:\n",
    "df['ff_min'] = df[['uvw2_flux_frac', 'uvm2_flux_frac', 'uvw1_flux_frac']].min(axis=1)\n",
    "df['ff_avg'] = df[['uvw2_flux_frac', 'uvm2_flux_frac', 'uvw1_flux_frac']].mean(axis=1)\n",
    "\n",
    "# Add a column for how many filters are present \n",
    "sed_columns = ['uvw2_dered','uvm2_dered','uvw1_dered','U_dered','B_dered','V_dered','I_dered']\n",
    "df['n_filters'] = df[sed_columns].notna().sum(axis=1)\n",
    "\n",
    "# Average distance from zams \n",
    "color_labels = ['uvw2 - b','uvw2 - v', 'uvw2 - i', \n",
    "                'uvw1 - b', 'uvw1 - v','uvw1 - i', \n",
    "                'uvm2 - b', 'uvm2 - v', 'uvm2 - i']\n",
    "distance_labels = [f'{color} distance' for color in color_labels]\n",
    "df['avg_zdis'] = df[distance_labels].mean(axis=1)\n",
    "\n",
    "# Average distance weighted by errors (zsigma)\n",
    "for col in color_labels:\n",
    "    df[f'{col} zsigma'] = df[f'{col} distance'] / df[f'{col} err']\n",
    "zsigma_labels = [f'{color} zsigma' for color in color_labels]\n",
    "df['avg_zsigma'] = df[zsigma_labels].mean(axis=1)\n",
    "\n",
    "# Require that the source is blue in at least three color combinations\n",
    "df = df[df.n_blue>3]\n",
    "\n",
    "# Require that the flux fraction is above 10%\n",
    "df = df[df.ff_avg>0.1]\n",
    "\n",
    "# If the closest source is within 2.5\", require that the flux fraction be above 25%\n",
    "df = df.drop(df[(df.closest<2.5) & (df.ff_avg<0.25)].index)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Replace the key \n",
    "df['key'] = np.arange(len(df))\n",
    "\n",
    "print('After initial cuts: ', df.shape[0])\n",
    "\n",
    "ff_cut = 0.4\n",
    "zdis_cut = -0.4\n",
    "bump_cut = 2\n",
    "nfilter_cut = 6\n",
    "\n",
    "df.loc[df.avg_zdis < zdis_cut, 'cut'] = 'VB-G'\n",
    "\n",
    "df.loc[(df.avg_zdis < zdis_cut) & \n",
    "       (df.ff_avg > ff_cut) &\n",
    "       (df.n_bumps <= 1) & \n",
    "       (df.n_filters >= nfilter_cut), 'cut'] = 'VB-E'\n",
    "\n",
    "df.loc[df.avg_zdis >= zdis_cut, 'cut'] = 'B-G'\n",
    "\n",
    "df.loc[(df.avg_zdis >= zdis_cut) & \n",
    "       (df.ff_avg > ff_cut) &\n",
    "       (df.n_bumps <= 1) & \n",
    "       (df.n_filters >= nfilter_cut), 'cut'] = 'B-E'\n",
    "\n",
    "\n",
    "\n",
    "# Percentage in each\n",
    "print('Av in the SMC: ', smc_Av)\n",
    "print('Candidates in the SMC: ', df[df.galaxy == 'smc'].shape[0])\n",
    "print('Av in the LMC: ', lmc_Av)\n",
    "print('Candidates in the LMC: ', df[df.galaxy == 'lmc'].shape[0]) \n",
    "print('Total Percentages: ')\n",
    "print(df.cut.value_counts(normalize=True).sort_index())\n",
    "print(' ')\n",
    "print('Total Values: ')\n",
    "print(df.cut.value_counts().sort_index())\n",
    "print(' ')\n",
    "print('LMC Values: ')\n",
    "print(df[df.galaxy == 'lmc'].cut.value_counts().sort_index())\n",
    "print(' ')\n",
    "print('SMC Values: ')\n",
    "print(df[df.galaxy == 'smc'].cut.value_counts().sort_index())\n",
    "\n",
    "\n",
    "plt.title('Candidate Rankings')\n",
    "df.cut.value_counts().sort_index().plot.barh(color='k',alpha=0.5,label='total');\n",
    "df[df.galaxy == 'lmc'].cut.value_counts().sort_index().plot.barh(color='b',alpha=0.5,label='lmc');\n",
    "df[df.galaxy == 'smc'].cut.value_counts().sort_index().plot.barh(color='r',alpha=0.5,label='smc')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this just for ones that are candidates regarless of extinction (Av=0)\n",
    "# # Import candidate list \n",
    "# if lmc_Av == 0 and smc_Av == 0:\n",
    "#     directory = '/home/bethany/Projects/0_Data/0_SUMS_Catalogs/CandidateCatalog/'\n",
    "#     candidates = pd.read_csv(directory+'3_stripped_star_candidates.csv')\n",
    "#     candidates['blue_with_no_extinction'] = 'no'\n",
    "#     # Crossmatch df with candidates and save a column in candidates\n",
    "#     cand_co = SkyCoord(ra=candidates.ra,dec=candidates.dec,unit='deg')\n",
    "#     for ind, row in df.iterrows():\n",
    "#         df_co = SkyCoord(ra=row.ra,dec=row.dec,unit='deg')\n",
    "#         sep = df_co.separation(cand_co).arcsecond\n",
    "#         if np.min(sep) < 0.1:\n",
    "#             candidates.loc[np.argmin(sep),'blue_with_no_extinction'] = 'yes'\n",
    "#         else:\n",
    "#             print(sep)\n",
    "\n",
    "#     # Save the candidates\n",
    "#     candidates.to_csv(directory+'3_stripped_star_candidates_vary_extinction.csv',index=False)\n",
    "\n",
    "#     # What type of cut do the ones robust against extinction have?\n",
    "#     print(candidates.loc[candidates['blue_with_no_extinction'] == 'yes','cut'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# \n",
    "# og_df = pd.read_csv(directory+'3_stripped_star_candidates.csv')\n",
    "\n",
    "# df['blue_with_no_extinction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/bethany/Projects/0_Data/0_SUMS_Catalogs/CandidateCatalog/'\n",
    "df.to_csv(directory+'fiducial_extinction.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#og_df#[og_df.col1 == 11293]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
