{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a98c55-901c-4fa7-b093-cc0deb4d58fc",
   "metadata": {},
   "source": [
    "# Reduce catalog based on SEDs\n",
    "## January 2024\n",
    "### Primary author: Bethany Ludwig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54991373-feeb-4335-a823-1348da797da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "np.seterr(invalid='ignore')\n",
    "\n",
    "# Functions \n",
    "def check_stars(df):\n",
    "    # Make sure we have all the discovery stars \n",
    "    discovery_names = ['Star_1','Star_2','Star_3','Star_4','Star_5','Star_6','Star_7','Star_8','Star_9','Star_10','Star_11','Star_12','Star_13','Star_14','Star_16','Star_17','Star_18','Star_20','Star_21','Star_22','Star_23','Star_24','Star_25']\n",
    "    c = 0\n",
    "    for star in discovery_names:\n",
    "        if star not in df.discovery_name.unique():\n",
    "            print (star)\n",
    "            c += 1\n",
    "    if c == 0:\n",
    "        print (\"All Remaining Discovery Stars After Magnitude Reductions Have Been Found\")\n",
    "# Paths \n",
    "data_dir = os.getenv(\"DATADIR\")\n",
    "directory = data_dir + '/0_SUMS_Catalogs/CandidateCatalog/'\n",
    "synth_photom_file = data_dir + '1_Models/StrippedStars/photometry_CMFGEN_composites.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20822f3f-ae85-42bd-a673-46de01069aba",
   "metadata": {},
   "source": [
    "## Load in photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c04a11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "galaxy\n",
      "lmc    8898\n",
      "smc    4445\n",
      "Name: count, dtype: int64\n",
      "How many stars we have:  13343\n",
      "All Remaining Discovery Stars After Magnitude Reductions Have Been Found\n"
     ]
    }
   ],
   "source": [
    "# Read in magnitude reduced files \n",
    "df = pd.read_csv(directory+'1_magnitude_reduced.csv') \n",
    "print(df.galaxy.value_counts())\n",
    "\n",
    "# Make a key\n",
    "df['key'] = np.arange(df.shape[0])\n",
    "\n",
    "# Rename filters for simplicity, we can rename them back at the end\n",
    "df = df.rename(columns={'uvw2_dered':'w2','uvm2_dered':'m2','uvw1_dered':'w1',\n",
    "                                          'U_dered':'u','B_dered':'b','V_dered':'v','I_dered':'i',\n",
    "                                          'uvw2 - b':'w2 - b', 'uvw2 - v':'w2 - v', 'uvw2 - i':'w2 - i',\n",
    "                                          'uvw1 - b':'w1 - b', 'uvw1 - v':'w1 - v', 'uvw1 - i':'w1 - i', \n",
    "                                          'uvm2 - b':'m2 - b', 'uvm2 - v':'m2 - v', 'uvm2 - i':'m2 - i'})\n",
    "# Select keys\n",
    "optical_columns = ['u','b','v','i']\n",
    "uv_columns = ['w2','m2','w1']\n",
    "color_columns = ['w2 - b', 'w2 - v', 'w2 - i',\n",
    "                'm2 - b', 'm2 - v', 'm2 - i',\n",
    "                'w1 - b', 'w1 - v', 'w1 - i']\n",
    "max_mag_err = 0.217\n",
    "\n",
    "\n",
    "# Print how many stars we have\n",
    "print(\"How many stars we have: \",df.shape[0])\n",
    "\n",
    "######################################################################################################\n",
    "# \"We use the DGL+23 composite stripped star plus MS model grid described in §5.1.2 to describe the  #\n",
    "# “expected” properties of such systems [binaries containing stripped stars].\"                       #\n",
    "######################################################################################################\n",
    "names = ['Minit_strip','M_MS','frac_MS','U','B','V','R','I','UVM2','UVW2','UVW1']\n",
    "sf = pd.read_csv(synth_photom_file,comment='#',delimiter='\\t',names=names)\n",
    "\n",
    "# Make dictionary of the minimum and maximum difference between different filters\n",
    "min_diff = {'w2 - m2': np.min(sf.UVW2-sf.UVM2) - max_mag_err,\n",
    "            'm2 - w1': np.min(sf.UVM2-sf.UVW1) - max_mag_err,\n",
    "            'w1 - u': np.min(sf.UVW1-sf.U) - max_mag_err,\n",
    "            'u - b': np.min(sf.U-sf.B) - max_mag_err,\n",
    "            'b - v': np.min(sf.B-sf.V) - max_mag_err,\n",
    "            'v - i': np.min(sf.V-sf.I) - max_mag_err,\n",
    "            # Additional UV - Optical Filters\n",
    "            'w1 - b': np.min(sf.UVW1-sf.B) - max_mag_err,\n",
    "            'm2 - u': np.min(sf.UVM2-sf.U) - max_mag_err,\n",
    "            'm2 - b': np.min(sf.UVM2-sf.B) - max_mag_err,\n",
    "           }\n",
    "\n",
    "max_diff = {'w2 - m2': np.max(sf.UVW2-sf.UVM2) + max_mag_err,\n",
    "            'm2 - w1': np.max(sf.UVM2-sf.UVW1) + max_mag_err,\n",
    "            'w1 - u': np.max(sf.UVW1-sf.U) + max_mag_err,\n",
    "            'u - b': np.max(sf.U-sf.B) + max_mag_err,\n",
    "            'b - v': np.max(sf.B-sf.V) + max_mag_err,\n",
    "            'v - i': np.max(sf.V-sf.I) + max_mag_err,\n",
    "            # Additional UV - Optical Filters\n",
    "            'w1 - b': np.max(sf.UVW1-sf.B) + max_mag_err,\n",
    "            'm2 - u': np.max(sf.UVM2-sf.U) + max_mag_err,\n",
    "            'm2 - b': np.max(sf.UVM2-sf.B) + max_mag_err,\n",
    "           }\n",
    "\n",
    "check_stars(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b958b46e-68fe-4e23-b99c-07f6437b1904",
   "metadata": {},
   "source": [
    "#### If blue due to one filter, check that that filter is not super different from adjacent filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e546c",
   "metadata": {},
   "source": [
    "# UV Optical Source Mismatches \n",
    "#### #1 Remove sources that have a uv-optical mismatch \n",
    "\"We first exclude sources for which the UV and optical magnitudes each show very little spread in observed magnitude within their respective groups, while the two groups themselves exhibit significant separation from each other.\n",
    "We consider the optical and/or UV photometry to show little variation if the standard deviation of the magnitudes\n",
    "is less than 0.217 mag (the maximum statistical error we allowed for a photometric point to be considered in our\n",
    "analysis) and we consider the UV and optical magnitudes to be “significantly separated” if the means of each group are separated by >1 AB mag in excess of the maximum photometric error.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40972211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many we have:  13043\n",
      "How many we lost:  300\n",
      "All Remaining Discovery Stars After Magnitude Reductions Have Been Found\n"
     ]
    }
   ],
   "source": [
    "size = df.shape[0]\n",
    "# Mismatch #1: UV and Optical components of SED are fairly flat but there's a large discrepency between them\n",
    "\n",
    "# If all the mags are within the max allowed error, we consider it 'flat'\n",
    "flat_std = max_mag_err\n",
    "flat_mag_jump = 1. + max_mag_err\n",
    "\n",
    "flat_jump_index = []\n",
    "\n",
    "for ind,row in df.iterrows():\n",
    "    uv = row[uv_columns].values\n",
    "    opt = row[optical_columns].values\n",
    "    \n",
    "    if np.nanstd(uv) < flat_std and np.nanstd(opt) < flat_std:\n",
    "        # If you have a flat sed look for a big jump \n",
    "        if np.abs(np.nanmean(uv) - np.nanmean(opt)) > flat_mag_jump:\n",
    "            flat_jump_index.append(row['key'])\n",
    "            \n",
    "# Remove from sample \n",
    "df = df[~df['key'].isin(flat_jump_index)]\n",
    "\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many we lost: ',size - df.shape[0])\n",
    "check_stars(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2ab05f",
   "metadata": {},
   "source": [
    "#### #2 Remove sources that have a uv-optical mismatch \n",
    "We additionally exclude sources where the most adjacent filters between the UV and optical groups (typically\n",
    "UVW1 and U-band, but if either are missing we utilize UVM2/B-band) are separated by an amount that is more\n",
    "than 0.217 mag larger than the biggest separation found between those filters in the helium plus MS star composite\n",
    "model grid. When carrying out this analysis, we allow for the possibility of a single poorly estimated magnitude by\n",
    "checking the next most adjacent magnitude difference as well (i.e. if the UVW1-U color of a source is too large, but\n",
    "UVW1-B color is within the range allowed by the composite model grid we do not exclude it at this stage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adae42f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many we have:  11629\n",
      "How many were categorized as mismatched:  1414\n",
      "All Remaining Discovery Stars After Magnitude Reductions Have Been Found\n"
     ]
    }
   ],
   "source": [
    "size = df.shape[0]\n",
    "# Mismatch #2: Check either UVW1 or UVW2 against U or B to see if there's a large jump \n",
    "def not_in_bin(row,uv_filter,optical_filter):\n",
    "    diff = row[uv_filter] - row[optical_filter]\n",
    "    if diff < min_diff[f'{uv_filter} - {optical_filter}'] or diff > max_diff[f'{uv_filter} - {optical_filter}']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def exists(row,Filter):\n",
    "    return np.isfinite(row[Filter])\n",
    "\n",
    "mismatch_index = []\n",
    "\n",
    "for i,r in df.iterrows():\n",
    "\n",
    "    # Ideal case: UVW1, U, and B, all exist. \n",
    "    if exists(r,'w1') and exists(r,'u') and exists(r,'b'):\n",
    "        # If UVW1 - U and UVW1 - B are both not in synthetic bin then drop\n",
    "        if not_in_bin(r,'w1','u') and not_in_bin(r,'w1','b'):\n",
    "            mismatch_index.append(r['key'])\n",
    "    \n",
    "    # UVW1 and U exist, but B does not.\n",
    "    if exists(r,'w1') and exists(r,'u') and not exists(r,'b'):\n",
    "        # If UVW1 - U is not in synthetic bin then drop\n",
    "        if not_in_bin(r,'w1','u'):\n",
    "            mismatch_index.append(r['key'])\n",
    "            \n",
    "    # UVW1 and B exist, but U does not. \n",
    "    if exists(r,'w1') and exists(r,'b') and not exists(r,'u'):\n",
    "        # If UVW1 - B is not in synthetic bin then drop\n",
    "        if not_in_bin(r,'w1','b'):\n",
    "            mismatch_index.append(r['key'])    \n",
    "    \n",
    "    # UVM2, U, and B, exist, but UVW1 does not. \n",
    "    if exists(r,'m2') and exists(r,'u') and exists(r,'b') and not exists(r,'w1'):\n",
    "        # If UVM2 - U and UVM2 - B are both not in synthetic bin then drop\n",
    "        if not_in_bin(r,'m2','u') and not_in_bin(r,'m2','b'):\n",
    "            mismatch_index.append(r['key']) \n",
    "            \n",
    "    # UVM2 and U exist, but UVW1 and B do not.\n",
    "    if exists(r,'m2') and exists(r,'u') and not exists(r,'w1') and not exists(r,'b'):\n",
    "        # If UVM2 - U is not in synthetic bin then drop\n",
    "        if not_in_bin(r,'m2','u'):\n",
    "            mismatch_index.append(r['key'])     \n",
    "\n",
    "    # UVM2 and B exist, but UVW1 and U do not. \n",
    "    if exists(r,'m2') and exists(r,'b') and not exists(r,'w1') and not exists(r,'u'):\n",
    "        # If UVM2 - B is not in synthetic bin then drop\n",
    "        if not_in_bin(r,'m2','b'):\n",
    "            mismatch_index.append(r['key'])    \n",
    "            \n",
    "df = df[~df['key'].isin(mismatch_index)]\n",
    "\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many were categorized as mismatched: ',size - df.shape[0])\n",
    "check_stars(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee269b91",
   "metadata": {},
   "source": [
    "# Optically-red SEDs:\n",
    "When examining the SEDs in our sample, we found some sources that appear to progressively decrease in flux from the UV to blue optical bands, but then increase in flux again when moving to progressively redder optical bands (resulting in a “V”-like SED). While these may be interesting sources in their own right, they are not consistent with expectations for helium star plus MS star binaries with absolute magnitudes in the range of our search. We therefore remove any sources that increase in flux between\n",
    "two or more adjacent optical filters (i.e. from U to B, B to V, and/or V to I)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "792f547d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many we have:  7707\n",
      "How many we lost:  3922\n",
      "All Remaining Discovery Stars After Magnitude Reductions Have Been Found\n"
     ]
    }
   ],
   "source": [
    "size = df.shape[0]\n",
    "red_index = []\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    y = np.array(row[optical_columns].values).astype(float)\n",
    "    # Calculate derivatives\n",
    "    d = np.diff(y)\n",
    "    # If derivatives are negative 2 or more times (indicating positive slope for mags) then save\n",
    "    n = len(d[np.isfinite(d) & (d<0)])\n",
    "    if n >= 2:\n",
    "        red_index.append(row['key'])\n",
    "\n",
    "df = df[~df['key'].isin(red_index)].reset_index(drop=True)\n",
    "\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many we lost: ',size-df.shape[0])\n",
    "check_stars(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3900ee35",
   "metadata": {},
   "source": [
    "# Poor-quality photometric points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b36b4833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many we have:  7027\n",
      "How many we lost:  680\n",
      "All Remaining Discovery Stars After Magnitude Reductions Have Been Found\n"
     ]
    }
   ],
   "source": [
    "vf = df.copy()\n",
    "\n",
    "def not_in_bin(row,uv_filter,optical_filter):\n",
    "    diff = row[uv_filter] - row[optical_filter]\n",
    "    if diff < min_diff[f'{uv_filter} - {optical_filter}'] or diff > max_diff[f'{uv_filter} - {optical_filter}']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "variable_index = []\n",
    "filters = ['w2','m2','w1','u','b','v','i']\n",
    "for ind,row in vf.iterrows():\n",
    "    # Get the sed\n",
    "    sed = row[filters]\n",
    "    # Take the derivatives         \n",
    "    div = np.abs(np.diff(sed))\n",
    "    # Compare to allowed differences \n",
    "    compare = [not_in_bin(row,f1,f2) for f1,f2 in zip(filters[:-1],filters[1:])]\n",
    "    # Where do the bumps occur? \n",
    "    loc = np.where(compare)[0]\n",
    "    # How many bumps are there?\n",
    "    n_bumps = len(loc)\n",
    "    if n_bumps == 0: \n",
    "        continue\n",
    "    # \"If more than three colors were flagged as suspect, we reject the source from our sample due to either having a poor\n",
    "    # quality SED or varying dramatically from expectations for stripped star binaries\"\n",
    "    if n_bumps >= 3:\n",
    "        variable_index.append(row.key)\n",
    "        \n",
    "        \n",
    "    # \"If two adjacent colors were flagged, then we remove the middle photometric \n",
    "    # point and assess whether the source would still be considered bluewards of the ZAMS based\n",
    "    # on the method in Section 5.3.\"\n",
    "    if n_bumps == 2 and (loc[1] == loc[0] - 1 or loc[1] == loc[0] + 1): \n",
    "        # UVM2 is connected\n",
    "        if loc[0] == 0 and loc[1] == 1:\n",
    "            vf.loc[vf.key==row.key,color_columns[1]] = np.nan\n",
    "        # UVW1 is connected\n",
    "        if loc[0] == 1 and loc[1] == 2:\n",
    "            vf.loc[vf.key==row.key,color_columns[2]] = np.nan\n",
    "        # B is connected, zero out related colors\n",
    "        if loc[0] == 3 and loc[1] == 4:\n",
    "            vf.loc[vf.key==row.key,color_columns[4]] = np.nan\n",
    "        # V is connected, zero out related colors\n",
    "        if loc[0] == 4 and loc[1] == 5:\n",
    "            vf.loc[vf.key==row.key,color_columns[5]] = np.nan\n",
    "            \n",
    "    # \"If only one color (or two non-adjacent colors) are flagged, then we remove both relevant magnitudes and assess\n",
    "    # whether the source would still be considered bluewards of the ZAMS.\" \n",
    "    else:\n",
    "        # UVW2 and UVM2 \n",
    "        if 0 in loc:\n",
    "            vf.loc[vf.key==row.key,color_columns[0] + color_columns[1]] = np.nan\n",
    "        # UVM2 and UVW1 \n",
    "        if 1 in loc: \n",
    "            vf.loc[vf.key==row.key,color_columns[1] + color_columns[2]] = np.nan\n",
    "        # UVW1 and U (we don't color by U)\n",
    "        if 2 in loc: \n",
    "            vf.loc[vf.key==row.key,color_columns[2]] = np.nan\n",
    "        # U and B (we don't color by U)\n",
    "        if 3 in loc: \n",
    "            vf.loc[vf.key==row.key,color_columns[4]] = np.nan\n",
    "        # B and V \n",
    "        if 4 in loc: \n",
    "            vf.loc[vf.key==row.key,color_columns[4] + color_columns[5]] = np.nan\n",
    "        # V and I \n",
    "        if 5 in loc: \n",
    "            vf.loc[vf.key==row.key,color_columns[5] + color_columns[6]] = np.nan\n",
    "            \n",
    "# Recalculate to see what is still blue \n",
    "n_blue = vf[color_columns].isin(['blue']).sum(axis=1)\n",
    "\n",
    "# Find out which rows are no longer blue \n",
    "nolongerblue = vf.loc[n_blue == 0,'key']\n",
    "\n",
    "# Combine Variable Index and No Longer Blue, Remove Duplicates\n",
    "variable_index = np.sort(np.unique(np.append(variable_index,nolongerblue)))\n",
    "\n",
    "# Drop variables\n",
    "df = df[~df['key'].isin(variable_index)]\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many we lost: ',len(variable_index))\n",
    "check_stars(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c87966-fddf-4e21-a5e1-66fd2940732c",
   "metadata": {},
   "source": [
    "# Faint I-band photometry: \n",
    "When examining the remaining sources in our sample, we noted multiple occasions where the MCPS I-band photometry appears significantly fainter than would be expected from extrapolating the rest of the optical SED. We note that while all of these objects would likely have V-I colors that fall with the overall range of composite model grid (due to the previous criteria for inclusion), this does not necessarily imply that it is consistent with expectations based on the rest of the SED. We therefore test whether the remaining objects would still be considered bluewards of the ZAMS if we remove the I-band. We remove any objects\n",
    "that only show a UV excess due to this band.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f039e26-6102-4b5e-8cc1-e50d1254f7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many we have:  5184\n",
      "How many we lost:  1843\n",
      "Star_17\n",
      "Star_25\n"
     ]
    }
   ],
   "source": [
    "# Change all color combos with 'i' to not be blue. \n",
    "i_df = df.copy()\n",
    "\n",
    "for color in ['w2 - i','w1 - i', 'm2 - i']:\n",
    "    i_df[color] = i_df[color].replace('blue',np.nan)\n",
    "\n",
    "# Recalculate to see what is still blue \n",
    "n_blue = i_df[color_columns].isin(['blue']).sum(axis=1)\n",
    "\n",
    "# Find out which rows are no longer blue \n",
    "bad_i_index = i_df.loc[n_blue == 0,'key']\n",
    "\n",
    "# Drop variables\n",
    "df = df[~df['key'].isin(bad_i_index)]\n",
    "print(f'How many we have: ',df.shape[0])\n",
    "print(f'How many we lost: ',len(bad_i_index))\n",
    "check_stars(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d481db",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2409d940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5184 stars remaining\n",
      "8159 stars cut\n",
      "galaxy\n",
      "lmc    3130\n",
      "smc    2054\n",
      "Name: count, dtype: int64\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "#Reread in and calculate the number of jumps for everything: \n",
    "df = pd.read_csv(directory+'1_magnitude_reduced.csv') \n",
    "\n",
    "# Rename filters for simplicity, we can rename them back at the end\n",
    "df = df.rename(columns={'uvw2_dered':'w2','uvm2_dered':'m2','uvw1_dered':'w1',\n",
    "                                          'U_dered':'u','B_dered':'b','V_dered':'v','I_dered':'i',\n",
    "                                          'uvw2 - b':'w2 - b', 'uvw2 - v':'w2 - v', 'uvw2 - i':'w2 - i',\n",
    "                                          'uvw1 - b':'w1 - b', 'uvw1 - v':'w1 - v', 'uvw1 - i':'w1 - i', \n",
    "                                          'uvm2 - b':'m2 - b', 'uvm2 - v':'m2 - v', 'uvm2 - i':'m2 - i'})\n",
    "\n",
    "#Recalculate the number of bumps for this sample and save it as a column: \n",
    "filters = ['w2','m2','w1','u','b','v','i']\n",
    "n_bumps = []\n",
    "for ind,row in df.iterrows():\n",
    "    # Get the sed\n",
    "    sed = row[filters]\n",
    "    # Take the derivatives         \n",
    "    div = np.abs(np.diff(sed))\n",
    "    # Compare to allowed differences \n",
    "    compare = [not_in_bin(row,f1,f2) for f1,f2 in zip(filters[:-1],filters[1:])]\n",
    "    # Where do the bumps occur? \n",
    "    loc = np.where(compare)[0]\n",
    "    # How many bumps are there?\n",
    "    n_bumps.append(len(loc))\n",
    "\n",
    "# Do any cuts overlap?\n",
    "drop_index = [flat_jump_index , mismatch_index , red_index , variable_index , bad_i_index]\n",
    "drop_name = ['flat_jump','mismatch','red','variable','bad_i']\n",
    "\n",
    "# Re-Read in magnitude reduced files \n",
    "df = pd.read_csv(directory+'1_magnitude_reduced.csv') \n",
    "\n",
    "# Make a key\n",
    "df['key'] = np.arange(df.shape[0])\n",
    "\n",
    "# Add the number of bumps to the dataframe\n",
    "df['n_bumps'] = n_bumps\n",
    "\n",
    "\n",
    "# Make a cut column \n",
    "df['cut'] = ''\n",
    "\n",
    "# Fill the cut column \n",
    "for index, name in zip(drop_index,drop_name):\n",
    "    df.loc[df['key'].isin(index),'cut'] = name\n",
    "\n",
    "print(f'{df[df.cut == \"\"].shape[0]} stars remaining')\n",
    "print(f'{df[df.cut != \"\"].shape[0]} stars cut')\n",
    "print(df[df.cut == \"\"].galaxy.value_counts())\n",
    "\n",
    "\n",
    "# Save the dataframe\n",
    "df.to_csv(directory+'2_sed_reduced.csv',index=False)\n",
    "print('Saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
